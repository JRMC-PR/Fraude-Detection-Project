I need a model that is going to take in data from a .csv file. The names of the lables  that it will be taking in are the following [REPORT_DATE, USER_ID, USER_NAME, TIMEZONE, IP_ADDRESS, IP_COUNTRY, IP_CITY, EVENT_TYPE ]. This model should be able to detect brute force attacks to user's accounts:
- Detect multiple attempts to log in using the same username but different numerical values. If the event_type column in the last attempt shows a succesful log in, print the row and add it to a file called "Fraud_(REPORT_DATE)".
- If multiple users try to log in from the same ip in a short timeframe. If the event_type column in the last attempt shows a succesful log in, print the row and add it to a file called "Fraud_(REPORT_DATE)".
- Learn the users regular log in hours to determine if they log in outside of those timeframes.
- If the user tried to log in multiple times within a short timeframe, i.e. more than 12 times in one minutes.
- The output of the model need to be a csv file that contains the date and the report of how many times a trigger was activated

Please explain your thought process and reasons why you made the choices in models and approaches.

Why we chose the model ( Isolation forest) For brute force:

----It is efficent for Large datasets
------- its time complexity is O(n 8 log(n)), wherer n is the number of samples.
----Handles Hih-Dimentional Data:
------- Works well even when the dataset has many features

1. Key Characteristics of Fraud Data
Fraud data typically has the following properties:

Rare (low frequency): Fraudulent transactions or activities make up a small portion of the dataset.
Diverse patterns: Fraud often involves unusual amounts, locations, times, or behaviors that don't match the "normal" patterns of activity.
Unlabeled data: In many cases, fraud data is not labeled, especially in real-time systems, making unsupervised models necessary.
Isolation Forest naturally aligns with these properties because it focuses on detecting anomalies rather than relying on predefined patterns.


Why Isolation Forest Is Better for Fraud Detection
1. Works Well with Unlabeled Data
Fraud detection is often an unsupervised problem:

You may not know which transactions are fraudulent (labeled data is scarce or unavailable).
Isolation Forest doesn't require labeled data to work, making it ideal for real-world fraud detection.
2. Focus on Anomalies
Fraudulent transactions are inherently anomalies in a dataset:

Isolation Forest isolates anomalies (fraud) by identifying data points that are "few and different" compared to the majority.
This makes it more directly focused on the nature of fraud compared to traditional classification models, which often need a lot of labeled training data.
3. Efficiency and Scalability
Fraud detection often involves large datasets with millions of transactions:

Isolation Forest is efficient, with a time complexity of
ùëÇ
(
ùëõ
‚ãÖ
log
‚Å°
(
ùëõ
)
)
O(n‚ãÖlog(n)), making it suitable for large datasets.
It randomly samples a subset of the data to create each isolation tree, reducing memory usage and computation time.
4. High-Dimensional Data Handling
Fraud detection involves many variables:

Transaction amount, time, location, payment method, user behavior, etc.
Isolation Forest handles high-dimensional datasets effectively without relying on feature scaling or distance metrics (as many clustering algorithms do).
5. Robust to Outliers and Noise
Fraudulent transactions can occur alongside noisy or unusual but valid data:

Isolation Forest is robust to noisy data because it works by isolating each point, focusing on patterns that stand out rather than aggregating data like clustering methods.
6. Contamination Parameter
Isolation Forest allows you to explicitly set the contamination parameter, which specifies the proportion of expected anomalies.
This is highly useful in fraud detection because you can tune the model to match the typical fraud rate in your data (e.g., 0.1% or 1%).

